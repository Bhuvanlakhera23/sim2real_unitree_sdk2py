üìú Go2 Locomotion Policy Contract (Sim ‚Üî Real)

Author: Bhuvan Lakhera
Robot: Unitree Go2 (12-DoF)
Policy Type: RL locomotion policy (position-target output)
Control Mode: Joint position PD
Execution Rate: 50 Hz (policy), ‚â•500 Hz inner loop (sim / firmware)

1. Purpose of This Document

This document defines the non-negotiable interface contract between:

a trained locomotion policy

the simulation environment

the real robot deployment stack

Any violation of this contract invalidates the policy and will result in unstable, biased, or unsafe behavior.

This is not a config file.
This is the ground truth specification.

2. Policy I/O Definition (Immutable)
2.1 Action Space (STRICT)
Property	Value
num_actions	12
Action range	[-1, 1] (normalized)
Semantic meaning	Œî joint position offsets
Output type	float32

Joint order (MUST NOT CHANGE):

[hip, thigh, calf] √ó [FL, FR, RL, RR]


Final target computation:

target_q = default_angles + action * action_scale


‚ö†Ô∏è The policy does not output torques.
‚ö†Ô∏è The policy does not know about PD gains.

2.2 Observation Space (STRICT)
Property	Value
num_obs	48
Observation order	Fixed
Normalization	Mandatory

Observation layout (index-accurate):

0‚Äì2    : base linear velocity (body frame) √ó lin_vel_scale
3‚Äì5    : base angular velocity (body frame) √ó ang_vel_scale
6‚Äì8    : gravity vector (projected)
9‚Äì11   : command [vx, vy, yaw_rate] √ó cmd_scale
12‚Äì23  : (q - default_angles) √ó dof_pos_scale
24‚Äì35  : dq √ó dof_vel_scale
36‚Äì47  : previous action


‚ùå Adding/removing/reordering entries breaks the policy
‚ùå Changing frames (world ‚Üî body) breaks the policy

3. Normalization Constants (Frozen)

These values are part of the trained model, not tunables.

Parameter	Value
lin_vel_scale	2.0
ang_vel_scale	0.25
dof_pos_scale	1.0
dof_vel_scale	0.05
action_scale	0.25

üîí These must be identical in:

training

MuJoCo simulation

hardware deployment

4. Timing Contract
4.1 Policy Timing (Immutable)
Property	Value
Policy rate	50 Hz
Control period	0.02 s
Execution	Deterministic

The policy assumes:

fixed-rate execution

no skipped steps

no variable dt

4.2 Inner Control Loop (Environment-dependent)
Environment	Inner Loop
MuJoCo	dt = 0.002 s, decimation = 10
Hardware	Firmware loop (~500 Hz)

‚úî Inner loop may differ
‚ùå Policy rate must not

5. Default Pose (Critical Reference)
default_angles:
  0.0, 0.80, -1.50,
  0.0, 0.80, -1.50,
  0.0, 1.00, -1.50,
  0.0, 1.00, -1.50


This pose is:

the zero-action equilibrium

the reference for all observations

assumed by the policy at reset

‚ö†Ô∏è Changing this requires retraining.

6. PD Control Layer (OUTSIDE Policy)

The policy is PD-agnostic.

PD gains:

may differ between sim and real

may be tuned for safety

must remain stable and overdamped

6.1 What PD Gains Affect
Effect	PD layer
Tracking stiffness	‚úÖ
Oscillation damping	‚úÖ
Torque magnitude	‚úÖ
Policy behavior	‚ùå (indirect only)
7. Command Interface
7.1 Command Semantics
cmd = [vx, vy, yaw_rate]


Body-frame

Continuous

Assumed smooth

7.2 Command Scaling
Environment	cmd_scale
Simulation	[2.0, 2.0, 0.25]
Hardware	[0.9, 0.4, 0.25]

‚úî Scaling may differ
‚ùå Command ordering may not

8. Allowed Modifications (Safe)

You may safely change:

PD gains

command limits

simulation timestep

terrain

domain randomization

logging / plotting

camera behavior

9. Forbidden Modifications (Policy-Breaking)

‚ùå Changing observation order
‚ùå Changing normalization constants
‚ùå Changing action semantics
‚ùå Changing default joint angles
‚ùå Mixing torque and position control
‚ùå Running policy at variable rate

Any of the above invalidates all results.

10. Versioning Rule

Each trained policy must be accompanied by:

this contract

the exact training config

the exact observation definition

Policy ‚â† file
Policy = file + contract

11. One-Line Summary (for collaborators)

‚ÄúIf it touches observations, normalization, action semantics, or timing ‚Äî retrain.
If it touches PD, commands, or physics ‚Äî tune.‚Äù
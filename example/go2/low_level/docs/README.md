
# Go2 Low-Level Control Stack (Simulation + Deployment)

> ‚ö†Ô∏è **Research Sandbox ‚Äî Use at Your Own Risk**  
> This directory is provided as a **research and experimentation sandbox**.  
> The author does **not take responsibility** for hardware damage, falls, or unsafe operation.  
> Always operate the robot in a **harnessed, open environment**.

---

## 1. Overview

This directory contains a **hardware-aligned low-level control pipeline** for the **Unitree Go2**, including:

- MuJoCo-based simulation
- Reinforcement learning policy inference
- Safe deployment via **joint position PD control**
- CSV-based logging for debugging and gait inspection

This stack is intended for **researchers and engineers** working on sim-to-real locomotion, not for production or consumer use.

---

## 2. Supported Scope & Limitations

This repository contains:

1. **Unitree SDK2 Python source code and official examples**
   - Located under `unitree_sdk2py/` and `example/`
   - Copyright ¬© Unitree Robotics

2. **Custom Go2 sim-to-real research stack**
   - Located under `example/go2/low_level/`
   - Developed for reinforcement learning based locomotion research
   - Not part of the official Unitree SDK

Only the Go2 low-level stack is actively developed in this repository.


### Supported
- ‚úÖ Unitree **Go2 only**
- ‚úÖ MuJoCo simulation
- ‚úÖ IsaacGym simulation
- ‚úÖ Joint position PD control
- ‚úÖ Pretrained locomotion policy (`policy_v1.pt`)
- ‚úÖ CSV logging for pose and gait inspection

### Not Supported
- ‚ùå Policy training (IsaacLab / IsaacGym not covered here)
- ‚ùå Torque control on hardware
- ‚ùå Other robots or morphologies
- ‚ùå Automatic recovery or fall detection
- ‚ùå Safety supervisors beyond PD + damping mode

---

## 3. Directory Structure (Relevant Subset)
```
low_level/
‚îú‚îÄ‚îÄ common/                  # Shared helpers (paths, constants, math)
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ sim/v1/              # MuJoCo simulation YAMLs
‚îÇ   ‚îî‚îÄ‚îÄ deploy/v1/           # Hardware deployment YAMLs
‚îú‚îÄ‚îÄ simulate/
‚îÇ   ‚îî‚îÄ‚îÄ mujoco/v1/           # MuJoCo simulation scripts + assets
‚îú‚îÄ‚îÄ deploy/
‚îÇ   ‚îî‚îÄ‚îÄ v1/                  # Hardware deployment scripts
‚îú‚îÄ‚îÄ debug/                   # Policy inspection, mode switching
‚îú‚îÄ‚îÄ policies/
‚îÇ   ‚îî‚îÄ‚îÄ policy_v1.pt         # Pretrained locomotion policy
‚îú‚îÄ‚îÄ plots/
‚îÇ   ‚îú‚îÄ‚îÄ sim_op/              # Simulation logs & plots
‚îÇ   ‚îî‚îÄ‚îÄ real_op/             # Hardware logs (if enabled)
```

---

## 4. Versioning Philosophy

- **v1.0**  
  First working version for a given policy.

- **v1.1**  
  Same control logic as v1.0, **adds CSV logging only**.

- **v2.x (future)**  
  Reserved for **newly trained policies**.

> All `v1.x` scripts are compatible with `policy_v1.pt`.

---

## 5. Policy Contract (Critical)

### 5.1 Policy Architecture

- Type: **MLP (no recurrence)**
- Input dimension: **48**
- Output dimension: **12**
- Output range: **unbounded (no tanh / clamp)**

### 5.2 What the Policy Outputs

The policy outputs a **12-D continuous vector** with torque-like statistics:

- Mean ‚âà ‚àí0.56  
- Std ‚âà 2.05  
- Max |value| ‚âà 4.73  

However:

> **Torque is never directly commanded.**

---

### 5.3 Deployment-Time Interpretation

During both simulation and hardware deployment, the policy output is **reinterpreted** as:

```
target_q = default_angles + action * action_scale
```

Where:
- `action` is clipped to `[-1, 1]`
- `action_scale` is defined in YAML
- `default_angles` define the standing posture

The resulting joint targets are tracked using **joint position PD control**.

‚ö†Ô∏è **Important:**  
This interpretation is a **deployment safety choice**, not something the policy was trained for.

---

## 6. Control Architecture (Sim & Real)
```
Observations (48D)
‚Üì
RL Policy (MLP)
‚Üì
Clipping + Scaling
‚Üì
Joint Target Positions
‚Üì
PD Controller
‚Üì
Motor Torques (implicit)
```

- No direct torque commands
- PD loop exists **outside** the policy
- PD gains are fully configurable via YAML

---

## 7. MuJoCo Simulation

### Primary Script
```
simulate/mujoco/v1/sim_walk_v1.0.py
```

### Experimental (Logging Only)
```
simulate/mujoco/v1/sim_walk_v1.1.py
```

### Run
```
cd example/go2/low_level/simulate/mujoco/v1
python3 sim_walk_v1.0.py go2_sim_v1.0.yaml
```

### Expected Behavior

* Robot stands symmetrically at default height
* Forward walking gait emerges
* Mild lateral drift to the **right** is expected
* Over long horizons, trajectory may curve rightward

This behavior reflects **policy bias**, not a bug.

---

## 8. Hardware Deployment (‚ö†Ô∏è Safety-Critical)

### Primary Script

```
deploy/v1/dep_walk_v1.0.py
```

### Experimental (Added Logging)

```
deploy/v1/dep_walk_v1.1.py
```

---

### 8.1 Network Interface Selection

Before deployment, identify the correct network interface:

```
ifconfig
```

Example (Ethernet-connected Go2):

```
eno1: inet 192.168.123.222  netmask 255.255.255.0
```

Use the interface name (e.g. `eno1`) when running deployment scripts.

‚ùå Using the wrong interface will cause DDS initialization failure.

---

### 8.2 Required Robot State (MANDATORY)

> **The robot must be SITTING before deployment.**

The deployment script:

* zeros motor torques
* takes low-level control

üö´ **Never start deployment from a standing robot**
unless the robot is **fully harnessed and lifted**.

---

### 8.3 Run Deployment

```
cd example/go2/low_level/deploy/v1
python3 dep_walk_v1.0.py eno1 go2_dep_v1.0.yaml
```
---

### 8.4 Safe Shutdown Procedure

1. **Primary (Recommended)**
   Press **SELECT** on the Unitree controller
   ‚Üí robot enters damping mode and sits down smoothly

2. **Emergency**

   ```
   CTRL+C
   ```

‚ö†Ô∏è Always:

* keep the robot harnessed
* operate in open space
* stand clear of legs during testing

---

## 9. Logging & Debugging

* v1.1 scripts generate CSV logs
* Used to:

  * inspect pose symmetry
  * analyze gait patterns
  * debug PD‚Äìpolicy interaction
* Logging does **not** change control behavior

---

## 10. Known Sim-to-Real Gaps

Be aware of the following **intentional mismatches**:

* Policy trained **without hardware awareness**
* MuJoCo has:

  * idealized contacts
  * implicit stabilizers
  * symmetric mass distribution
* Hardware requires:

  * higher PD stiffness
  * careful damping
  * compensation for asymmetry

As a result:

* Standing in sim is easier than on hardware
* Policy requires PD + stabilizer assistance to remain upright

Future versions (`v2.x`) will address this via **hardware-informed training**.

---

## 11. Final Notes

* YAML defines **control behavior**
* Python scripts **bind everything together**
* The policy itself is **fixed and opaque**
* This stack prioritizes **safety and inspectability** over performance

### Discarded / Reference Scripts

- `deploy_policy.py`  
  Deprecated and no longer used. Kept only for historical reference.

- `go2_stand_example.py`  
  Original Unitree SDK example. Not part of this control stack.

- `path_utils.py`
  Unified script for path definitions for simulation and deployment scripts.

